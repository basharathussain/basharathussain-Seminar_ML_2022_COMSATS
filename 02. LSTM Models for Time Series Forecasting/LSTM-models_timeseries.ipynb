{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM-models_timeseries.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPGBO2ozRexRrLx+ITrwIgw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Prepared by Basharat Hussain on 21/8/2022\n","This tutorial is modified version from machinelearningmastery.com"],"metadata":{"id":"6Mr6O5W9_JXK"}},{"cell_type":"markdown","source":["**Time series forecasting problems**\n","\n","*   How to develop LSTM models for univariate time series forecasting.\n","*   How to develop LSTM models for multivariate time series forecasting.\n","*   How to develop LSTM models for multi-step time series forecasting."],"metadata":{"id":"4RkQ_vsuwlf5"}},{"cell_type":"markdown","source":["**Prepration Steps -- access Google Drive and Mount Dataset**\n"," "],"metadata":{"id":"vXX_51Bb0rCc"}},{"cell_type":"markdown","source":["This tutorial is divided into four parts; they are:\n","\n","1. Univariate LSTM Models\n","    * Data Preparation\n","    * Vanilla LSTM\n","    * Stacked LSTM\n","    * Bidirectional LSTM\n","    * CNN LSTM\n","    * ConvLSTM\n","2. Multivariate LSTM Models\n","    * Multiple Input Series.\n","    * Multiple Parallel Series.\n","3. Multi-Step LSTM Models\n","    * Data Preparation\n","    * Vector Output Model\n","    * Encoder-Decoder Model\n","4. Multivariate Multi-Step LSTM Models\n","    * Multiple Input Multi-Step Output.\n","    * Multiple Parallel Input and Multi-Step Output."],"metadata":{"id":"mhHvUYQyKojP"}},{"cell_type":"markdown","source":["# Univariate LSTM Models"],"metadata":{"id":"u4E5q9kZLKJY"}},{"cell_type":"markdown","source":["**1.1 Data Preparation**"],"metadata":{"id":"Sco7kzZyLOX3"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","dataset_path = \"/content/drive/My Drive/Google-CoLab/Seminar_ML_2022_CAMSATS/02. LSTM Models for Time Series Forecasting/pima-indians-diabetes.data.csv\"\n","dataset_path"],"metadata":{"id":"DFl7Ophn00Yi","colab":{"base_uri":"https://localhost:8080/","height":91},"executionInfo":{"status":"ok","timestamp":1661149267873,"user_tz":-300,"elapsed":23119,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"be0a42bd-1e5d-4fa5-ec88-3fd163d01d7f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Google-CoLab/Seminar_ML_2022_CAMSATS/02. LSTM Models for Time Series Forecasting/pima-indians-diabetes.data.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/My Drive/Google-CoLab/Seminar_ML_2022_CAMSATS/02. LSTM Models for Time Series Forecasting/pima-indians-diabetes.data.csv'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["**1. Load Data**\n","\n","define input sequence\n","\n","raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n"," \n","We divide the sequence into multiple input/output patterns called samples.\n","\n","X,  y\n","\n","10, 20, 30\t>\t   40\n","\n","20, 30, 40\t>\t50\n","\n","30, 40, 50\t>\t60"],"metadata":{"id":"hLSQRUR9zd-S"}},{"cell_type":"code","source":["# define input sequence\n","raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n","# choose a number of time steps\n","n_steps = 3"],"metadata":{"id":"4mNOV2E7OUM2"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":10,"metadata":{"id":"EPflVP9PwezD","executionInfo":{"status":"ok","timestamp":1661150355805,"user_tz":-300,"elapsed":446,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}}},"outputs":[],"source":["# first neural network with keras tutorial\n","# univariate data preparation\n","from numpy import array\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","\n","\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"6J1im_GyOoAL","executionInfo":{"status":"ok","timestamp":1661150359631,"user_tz":-300,"elapsed":438,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["1.1 Split input sequence into array of Samples\n","\n","Make a split function to convert [10, 20, 30, 40, 50, 60, 70, 80, 90] into sliding window samples "],"metadata":{"id":"pdgIezCpOhQ2"}},{"cell_type":"code","source":["# split a univariate sequence into samples\n","def split_sequence(sequence, n_steps):\n","\tX, y = list(), list()\n","\tfor i in range(len(sequence)):\n","\t\t# find the end of this pattern\n","\t\tend_ix = i + n_steps\n","\t\t# check if we are beyond the sequence\n","\t\tif end_ix > len(sequence)-1:\n","\t\t\tbreak\n","\t\t# gather input and output parts of the pattern\n","\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","\t\tX.append(seq_x)\n","\t\ty.append(seq_y)\n","\treturn array(X), array(y)"],"metadata":{"id":"zrw1v6MMOKM3","executionInfo":{"status":"ok","timestamp":1661150361317,"user_tz":-300,"elapsed":2,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["Actual call of above function on inout sequence"],"metadata":{"id":"16FSPboC2y-K"}},{"cell_type":"code","source":["# split into samples\n","X, y = split_sequence(raw_seq, n_steps)\n","# summarize the data\n","for i in range(len(X)):\n","\tprint(X[i], y[i])"],"metadata":{"id":"30mppyhJzZVL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661150364784,"user_tz":-300,"elapsed":622,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"22cf84f3-55cb-42c9-feae-83fb2087ef57"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[10 20 30] 40\n","[20 30 40] 50\n","[30 40 50] 60\n","[40 50 60] 70\n","[50 60 70] 80\n","[60 70 80] 90\n"]}]},{"cell_type":"code","source":["print(X.shape)\n","print (y.shape)\n","print(X)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YPmjZ_rw5Pp6","executionInfo":{"status":"ok","timestamp":1661150366145,"user_tz":-300,"elapsed":6,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"e9c1c7dd-d6e3-4131-ced8-936066e8398d"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["(6, 3)\n","(6,)\n","[[10 20 30]\n"," [20 30 40]\n"," [30 40 50]\n"," [40 50 60]\n"," [50 60 70]\n"," [60 70 80]]\n"]}]},{"cell_type":"code","source":["# reshape from [samples, timesteps] into [samples, timesteps, features]\n","n_features = 1  # univariat ?\n","X = X.reshape((X.shape[0], X.shape[1], n_features))\n","for i in range(len(X)):\n","\tprint(X[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Lg_2-WYSAlO","executionInfo":{"status":"ok","timestamp":1661150504372,"user_tz":-300,"elapsed":423,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"48dac8e8-7ad8-4495-c03d-3a12ed16bff7"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["[[10]\n"," [20]\n"," [30]]\n","[[20]\n"," [30]\n"," [40]]\n","[[30]\n"," [40]\n"," [50]]\n","[[40]\n"," [50]\n"," [60]]\n","[[50]\n"," [60]\n"," [70]]\n","[[60]\n"," [70]\n"," [80]]\n"]}]},{"cell_type":"markdown","source":["**2. Define Keras Model (Vanilla LSTM)**"],"metadata":{"id":"GzmIMzr1wkzZ"}},{"cell_type":"code","source":["# define the keras model\n","# define model\n","model = Sequential()\n","model.add(LSTM(50, activation='relu', input_shape=(n_steps, n_features)))\n","model.add(Dense(1))\n"],"metadata":{"id":"mm4tC5v757Dq","executionInfo":{"status":"ok","timestamp":1661150545766,"user_tz":-300,"elapsed":752,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["**3. Compile Keras Model**\n","\n"],"metadata":{"id":"u5nYjxSj6G2R"}},{"cell_type":"code","source":["# compile the keras model\n","model.compile(optimizer='adam', loss='mse')"],"metadata":{"id":"VGeE_nuY6NOb","executionInfo":{"status":"ok","timestamp":1661150572933,"user_tz":-300,"elapsed":693,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["you can print summary of the compiled Model\n"],"metadata":{"id":"QHCr9NQvGjWB"}},{"cell_type":"code","source":["# Print a summary of the Keras model:\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"63Vp8BxsGoGn","executionInfo":{"status":"ok","timestamp":1661150581600,"user_tz":-300,"elapsed":1122,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"67a4b740-5510-4c47-b678-a9b998a2bb68"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 50)                10400     \n","                                                                 \n"," dense (Dense)               (None, 1)                 51        \n","                                                                 \n","=================================================================\n","Total params: 10,451\n","Trainable params: 10,451\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["**4. Fit Keras Model**\n","\n","Training occurs over epochs, and each epoch is split into batches.\n","\n","**Epoch**: One pass through all of the rows in the training dataset\n","\n","**Batch**: One or more samples considered by the model within an epoch before weights are updated"],"metadata":{"id":"ky_PI7vS6Qaa"}},{"cell_type":"code","source":["# fit the keras model on the dataset\n","model.fit(X, y, epochs=200, verbose=0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ucEA8uCH6eut","executionInfo":{"status":"ok","timestamp":1661150753499,"user_tz":-300,"elapsed":930,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"a81463ae-720d-4367-cf17-1604d3cc71bf"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f6550945190>"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["**5. Make Predictions**\n","\n","“After I train my model, how can I use it to make predictions on new data?”"],"metadata":{"id":"XdQBadl48ClK"}},{"cell_type":"code","source":["from termcolor import colored\n","print(colored(\"hello red world **BOLD TEXT**\", 'red'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S-8B_7V28-Rp","executionInfo":{"status":"ok","timestamp":1661150771199,"user_tz":-300,"elapsed":381,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"60431db8-866c-414f-876c-835a4e65be99"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mhello red world **BOLD TEXT**\u001b[0m\n"]}]},{"cell_type":"code","source":["# make probability predictions with the model\n","x_input_new = array([70, 80, 90])\n","y_input_new = 100\n","\n","x_input_new = x_input_new.reshape((1, n_steps, n_features))\n","yhat = model.predict(x_input_new, verbose=0)\n","print(yhat)\n","\n","print('%s => %f (expected %d)' % (x_input_new.tolist(), yhat, y_input_new))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-xX_P1XO8J_a","executionInfo":{"status":"ok","timestamp":1661150973134,"user_tz":-300,"elapsed":361,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"0f990dc8-b657-46c8-90ac-2bf5ad498e28"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["[[100.59877]]\n","[[[70], [80], [90]]] => 100.598770 (expected 100)\n"]}]},{"cell_type":"markdown","source":["# 1.2 Stacked LSTM"],"metadata":{"id":"uKvE7Mz8UTG1"}},{"cell_type":"code","source":["# define model\n","model = Sequential()\n","model.add(LSTM(50, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n","model.add(LSTM(50, activation='relu'))\n","model.add(Dense(1))\n","\n","\n","model.compile(optimizer='adam', loss='mse')\n","\n","# fit model\n","model.fit(X, y, epochs=200, verbose=0)\n","# demonstrate prediction\n","x_input = array([70, 80, 90])\n","x_input = x_input.reshape((1, n_steps, n_features))\n","yhat = model.predict(x_input, verbose=0)\n","print(yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OmwnBdMTUXaG","executionInfo":{"status":"ok","timestamp":1661151078347,"user_tz":-300,"elapsed":3555,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"669459ec-8756-4842-aa5b-d0efa33fd474"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["[[103.701935]]\n"]}]},{"cell_type":"markdown","source":["# 1.3 Bidirectional LSTM"],"metadata":{"id":"ARUw3QBaUizl"}},{"cell_type":"code","source":["from tensorflow.keras.layers import Bidirectional\n","\n","# define model\n","model = Sequential()\n","model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(n_steps, n_features)))\n","model.add(Dense(1))\n","\n","model.compile(optimizer='adam', loss='mse')\n","# fit model\n","model.fit(X, y, epochs=200, verbose=0)\n","# demonstrate prediction\n","x_input = array([70, 80, 90])\n","x_input = x_input.reshape((1, n_steps, n_features))\n","yhat = model.predict(x_input, verbose=0)\n","print(yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmlKECv8Um71","executionInfo":{"status":"ok","timestamp":1661151159183,"user_tz":-300,"elapsed":4258,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"fe739d48-3662-49f4-e56e-e567c2f0ba23"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["[[101.65765]]\n"]}]},{"cell_type":"markdown","source":["# 1.4 CNN LSTM\n","\n","\n","[samples, subsequences, timesteps, features]"],"metadata":{"id":"YXa6fh1zVSfV"}},{"cell_type":"code","source":["# univariate cnn lstm example\n","from numpy import array\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import TimeDistributed\n","from keras.layers.convolutional import Conv1D\n","from keras.layers.convolutional import MaxPooling1D\n"," \n","# split a univariate sequence into samples\n","def split_sequence(sequence, n_steps):\n","\tX, y = list(), list()\n","\tfor i in range(len(sequence)):\n","\t\t# find the end of this pattern\n","\t\tend_ix = i + n_steps\n","\t\t# check if we are beyond the sequence\n","\t\tif end_ix > len(sequence)-1:\n","\t\t\tbreak\n","\t\t# gather input and output parts of the pattern\n","\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","\t\tX.append(seq_x)\n","\t\ty.append(seq_y)\n","\treturn array(X), array(y)\n"," \n","# define input sequence\n","raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n","# choose a number of time steps\n","n_steps = 4\n","# split into samples\n","X, y = split_sequence(raw_seq, n_steps)\n","\n","print(X.shape)\n","print (y.shape)\n","print (X)\n","print (y)\n","\n","# reshape from [samples, timesteps] into [samples, subsequences, timesteps, features]\n","n_features = 1\n","n_seq = 2\n","n_steps = 2\n","X = X.reshape((X.shape[0], n_seq, n_steps, n_features))\n","\n","print(X.shape)\n","print (y.shape)\n","print (X)\n","print (y)\n","\n","# define model\n","model = Sequential()\n","model.add(TimeDistributed(Conv1D(filters=64, kernel_size=1, activation='relu'), input_shape=(None, n_steps, n_features)))\n","model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n","model.add(TimeDistributed(Flatten()))\n","model.add(LSTM(50, activation='relu'))\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mse')\n","# fit model\n","model.fit(X, y, epochs=500, verbose=0)\n","# demonstrate prediction\n","x_input = array([60, 70, 80, 90])\n","x_input = x_input.reshape((1, n_seq, n_steps, n_features))\n","print (x_input)\n","yhat = model.predict(x_input, verbose=0)\n","print(yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qVd7ugMMVVt9","executionInfo":{"status":"ok","timestamp":1661151941730,"user_tz":-300,"elapsed":5411,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"1f99826a-4e9e-4c81-e58c-69f5ab82d5ba"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["(5, 4)\n","(5,)\n","[[10 20 30 40]\n"," [20 30 40 50]\n"," [30 40 50 60]\n"," [40 50 60 70]\n"," [50 60 70 80]]\n","[50 60 70 80 90]\n","(5, 2, 2, 1)\n","(5,)\n","[[[[10]\n","   [20]]\n","\n","  [[30]\n","   [40]]]\n","\n","\n"," [[[20]\n","   [30]]\n","\n","  [[40]\n","   [50]]]\n","\n","\n"," [[[30]\n","   [40]]\n","\n","  [[50]\n","   [60]]]\n","\n","\n"," [[[40]\n","   [50]]\n","\n","  [[60]\n","   [70]]]\n","\n","\n"," [[[50]\n","   [60]]\n","\n","  [[70]\n","   [80]]]]\n","[50 60 70 80 90]\n","[[[[60]\n","   [70]]\n","\n","  [[80]\n","   [90]]]]\n","[[100.889435]]\n"]}]},{"cell_type":"markdown","source":["# 1.5 ConvLSTM\n","\n","[samples, timesteps, rows, columns, features]"],"metadata":{"id":"q1krGFtNVlYn"}},{"cell_type":"code","source":["# univariate convlstm example\n","from numpy import array\n","from keras.models import Sequential\n","from keras.layers import LSTM\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import ConvLSTM2D\n"," \n","# split a univariate sequence into samples\n","def split_sequence(sequence, n_steps):\n","\tX, y = list(), list()\n","\tfor i in range(len(sequence)):\n","\t\t# find the end of this pattern\n","\t\tend_ix = i + n_steps\n","\t\t# check if we are beyond the sequence\n","\t\tif end_ix > len(sequence)-1:\n","\t\t\tbreak\n","\t\t# gather input and output parts of the pattern\n","\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n","\t\tX.append(seq_x)\n","\t\ty.append(seq_y)\n","\treturn array(X), array(y)\n"," \n","# define input sequence\n","raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n","# choose a number of time steps\n","n_steps = 4\n","# split into samples\n","X, y = split_sequence(raw_seq, n_steps)\n","# reshape from [samples, timesteps] into [samples, timesteps, rows, columns, features]\n","n_features = 1\n","n_seq = 2\n","n_steps = 2\n","X = X.reshape((X.shape[0], n_seq, 1, n_steps, n_features))\n","# define model\n","model = Sequential()\n","model.add(ConvLSTM2D(filters=64, kernel_size=(1,2), activation='relu', input_shape=(n_seq, 1, n_steps, n_features)))\n","model.add(Flatten())\n","model.add(Dense(1))\n","model.compile(optimizer='adam', loss='mse')\n","# fit model\n","model.fit(X, y, epochs=500, verbose=0)\n","# demonstrate prediction\n","x_input = array([60, 70, 80, 90])\n","x_input = x_input.reshape((1, n_seq, 1, n_steps, n_features))\n","yhat = model.predict(x_input, verbose=0)\n","print(yhat)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e10eZkOnVyoG","executionInfo":{"status":"ok","timestamp":1661151432100,"user_tz":-300,"elapsed":5118,"user":{"displayName":"Basharat Hussain","userId":"13397079541735527718"}},"outputId":"62026439-cad1-432f-c564-457c6e43bf07"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f654a917cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["[[103.26338]]\n"]}]}]}